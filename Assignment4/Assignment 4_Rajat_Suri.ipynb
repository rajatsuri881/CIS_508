{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rajatsuri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "#NLTK-------------------------------\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "# Import libraries for feature \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 2)\n",
      "(2070, 17)\n"
     ]
    }
   ],
   "source": [
    "#Read files\n",
    "\n",
    "textData = pd.read_csv('Comments.csv') #creates a dataframe\n",
    "\n",
    "CustInfoData = pd.read_csv('Customers.csv')  #creates a dataframe\n",
    "\n",
    "print(textData.shape)\n",
    "print(CustInfoData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 16)\n",
      "(2070, 2)\n",
      "     ID                                           Comments\n",
      "0  1309  Does not like the way the phone works. It is t...\n",
      "1  3556  Wanted to know the nearest store location. Wan...\n",
      "2  2230  Wants to know how to do text messaging. Referr...\n",
      "3  2312  Asked how to disable call waiting. referred hi...\n",
      "4  3327  Needs help learning how to use the phone. I su...\n",
      "0       Cancelled\n",
      "1         Current\n",
      "2         Current\n",
      "3         Current\n",
      "4       Cancelled\n",
      "          ...    \n",
      "2065    Cancelled\n",
      "2066    Cancelled\n",
      "2067    Cancelled\n",
      "2068    Cancelled\n",
      "2069    Cancelled\n",
      "Name: TARGET, Length: 2070, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Extract target column from Customer Info file\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
    "                     \n",
    "print(X_train.shape)\n",
    "print(textData.shape)\n",
    "print(textData.head())\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize - Split the sentences to lists of words\n",
    "textData['CommentsTokenized'] = textData['Comments'].apply(word_tokenize)\n",
    "\n",
    "export_csv = textData.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/textData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SnowballStemmer stemmer.\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#Now do stemming - create a new dataframe to store stemmed version\n",
    "newTextDataSS=pd.DataFrame()\n",
    "newTextDataSS=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
    "newTextDataSS['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "\n",
    "export_csv = newTextDataSS.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/newTextDataSS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PorterStemmer stemmer\n",
    "stemmer = PorterStemmer ()\n",
    "\n",
    "#Now do stemming - create a new dataframe to store stemmed version\n",
    "newTextDataPS=pd.DataFrame()\n",
    "newTextDataPS=textData.drop(columns=[\"CommentsTokenized\",\"Comments\"])\n",
    "newTextDataPS['CommentsTokenizedStemmed'] = textData['CommentsTokenized'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "\n",
    "export_csv = newTextDataPS.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/newTextDataPS.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Join stemmed strings\n",
    "newTextDataSS['CommentsTokenizedStemmed'] = newTextDataSS['CommentsTokenizedStemmed'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "export_csv = newTextDataSS.to_csv ('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/newTextDataSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 354)\n",
      "int64\n",
      "['3399', '3g', 'abysm', 'access', 'accessori', 'adapt', 'add', 'addit', 'additon', 'address', 'adit', 'adress', 'advertis', 'afraid', 'alway', 'angel', 'angri', 'ani', 'anoth', 'anyth', 'anytim', 'area', 'asap', 'ask', 'bad', 'basic', 'bateri', 'batteri', 'becaus', 'believ', 'better', 'bigger', 'book', 'bought', 'brain', 'bring', 'built', 'busi', 'button', 'buy', 'cancel', 'cancer', 'car', 'care', 'carrier', 'caus', 'cc', 'cell', 'certain', 'chang', 'charg', 'charger', 'check', 'chip', 'citi', 'claim', 'cleariti', 'cold', 'comapr', 'compani', 'compar', 'competit', 'complain', 'complaint', 'concept', 'connect', 'consisit', 'consist', 'constan', 'contact', 'continu', 'contract', 'correct', 'cost', 'coupl', 'cover', 'coverag', 'creat', 'credit', 'cstmer', 'cstmr', 'current', 'cust', 'custom', 'customr', 'date', 'day', 'dead', 'decent', 'defect', 'deo', 'did', 'die', 'differ', 'difficult', 'digiti', 'direct', 'disabl', 'doe', 'don', 'dont', 'drop', 'dure', 'easier', 'effect', 'encount', 'end', 'enemi', 'equip', 'everytim', 'everywher', 'evrey', 'exact', 'expect', 'expir', 'explain', 'facepl', 'fals', 'famili', 'featur', 'fed', 'figur', 'fine', 'fix', 'forev', 'forward', 'friend', 'function', 'furthermor', 'futur', 'gave', 'goat', 'good', 'great', 'gsm', 'handset', 'happi', 'hard', 'hate', 'hear', 'heard', 'help', 'higher', 'highway', 'hochi', 'hole', 'home', 'hope', 'horribl', 'hous', 'implement', 'improv', 'inadequ', 'includ', 'info', 'inform', 'ing', 'internet', 'intersect', 'issu', 'june', 'just', 'kid', 'kno', 'know', 'lame', 'later', 'lctn', 'learn', 'leroy', 'like', 'line', 'list', 'local', 'locat', 'locatn', 'long', 'los', 'lost', 'lot', 'love', 'major', 'make', 'manag', 'mani', 'manual', 'market', 'mean', 'messag', 'metropolitian', 'minut', 'misl', 'mistak', 'model', 'momma', 'mr', 'napeleon', 'near', 'nearest', 'need', 'network', 'new', 'news', 'notic', 'number', 'numer', 'offer', 'old', 'om', 'open', 'option', 'ori', 'ot', 'outbound', 'pass', 'pay', 'pda', 'peopl', 'perform', 'person', 'phone', 'piec', 'plan', 'pleas', 'point', 'polici', 'poor', 'possibl', 'probabl', 'problem', 'proper', 'provid', 'provis', 'purpos', 'rate', 'rater', 'realiz', 'realli', 'reason', 'receiv', 'recept', 'recption', 'reenter', 'refer', 'relat', 'rep', 'replac', 'respect', 'result', 'rid', 'right', 'ring', 'roam', 'roll', 'rubbish', 'rude', 'said', 'sale', 'say', 'screen', 'self', 'send', 'servic', 'shitti', 'shut', 'sign', 'signal', 'signific', 'simm', 'simpli', 'sinc', 'site', 'slow', 'sold', 'someon', 'sometim', 'soon', 'speak', 'speed', 'start', 'static', 'stole', 'store', 'stuff', 'stupid', 'substant', 'subtract', 'suck', 'suggest', 'supervisor', 'support', 'sure', 'surpris', 'suspect', 'suspend', 'switch', 'teach', 'technic', 'tell', 'terribl', 'test', 'text', 'think', 'thought', 'ticket', 'till', 'time', 'tire', 'today', 'toilet', 'told', 'tone', 'tower', 'transeff', 'transf', 'transfer', 'travel', 'tri', 'trust', 'turn', 'uncomfort', 'understand', 'unhappi', 'unlimit', 'unreli', 'unwil', 'upset', 'usag', 'use', 'useless', 'valu', 'veri', 'vm', 'wa', 'wait', 'want', 'wast', 'way', 'weak', 'web', 'websit', 'week', 'whi', 'wife', 'wish', 'wll', 'wold', 'work', 'wors', 'worst', 'wrong', 'xvyx', 'year', 'york']\n",
      "      0    1    2    3    4    5    6    7    8    9    ...  344  345  346  \\\n",
      "0       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "1       0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
      "2       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2065    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2066    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2067    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2068    0    0    0    0    0    0    0    0    0    1  ...    0    0    0   \n",
      "2069    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "      347  348  349  350  351  352  353  \n",
      "0       1    0    0    0    0    0    0  \n",
      "1       0    0    0    0    0    0    0  \n",
      "2       0    0    0    0    0    0    0  \n",
      "3       0    0    0    0    0    0    0  \n",
      "4       0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "2065    0    0    0    0    0    0    0  \n",
      "2066    0    0    0    0    0    0    0  \n",
      "2067    0    0    0    0    0    0    0  \n",
      "2068    0    0    0    0    0    0    0  \n",
      "2069    0    0    0    0    0    0    0  \n",
      "\n",
      "[2070 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "#Do Bag-Of-Words model - Term - Document Matrix\n",
    "#Learn the vocabulary dictionary and return term-document matrix.\n",
    "#count_vect = CountVectorizer(stop_words=None)\n",
    "count_vect = CountVectorizer(stop_words='english',lowercase=False)\n",
    "TD_counts = count_vect.fit_transform(newTextDataSS.CommentsTokenizedStemmed)\n",
    "print(TD_counts.shape)\n",
    "print(TD_counts.dtype)\n",
    "print(count_vect.get_feature_names())\n",
    "#print(TD_counts)\n",
    "DF_TD_Counts=pd.DataFrame(TD_counts.toarray())\n",
    "print(DF_TD_Counts)\n",
    "export_csv = DF_TD_Counts.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/DF_TD_Counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 354)\n",
      "      0    1    2    3        4    5    6    7    8         9    ...  344  \\\n",
      "0     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "1     0.0  0.0  0.0  0.0  0.27568  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "3     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "4     0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "...   ...  ...  ...  ...      ...  ...  ...  ...  ...       ...  ...  ...   \n",
      "2065  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2066  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2067  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "2068  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.772949  ...  0.0   \n",
      "2069  0.0  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
      "\n",
      "      345  346       347  348  349  350  351  352  353  \n",
      "0     0.0  0.0  0.209678  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...       ...  ...  ...  ...  ...  ...  ...  \n",
      "2065  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2066  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2067  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2068  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2069  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2070 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "#Compute TF-IDF Matrix\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(TD_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "DF_TF_IDF=pd.DataFrame(X_train_tfidf.toarray())\n",
    "print(DF_TF_IDF)\n",
    "export_csv= DF_TF_IDF.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/DF_TF_IDF.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 17)\n",
      "(2070, 16)\n",
      "(2070, 370)\n",
      "        ID Sex Status  Children  Est_Income Car_Owner   Usage        Age  \\\n",
      "0        1   F      S         1    38000.00         N  229.64  24.393333   \n",
      "1        6   M      M         2    29616.00         N   75.29  49.426667   \n",
      "2        8   M      M         0    19732.80         N   47.25  50.673333   \n",
      "3       11   M      S         2       96.33         N   59.01  56.473333   \n",
      "4       14   F      M         2    52004.80         N   28.14  25.140000   \n",
      "...    ...  ..    ...       ...         ...       ...     ...        ...   \n",
      "2065  3821   F      S         0    78851.30         N   29.04  48.373333   \n",
      "2066  3822   F      S         1    17540.70         Y   36.20  62.786667   \n",
      "2067  3823   F      M         0    83891.90         Y   74.40  61.020000   \n",
      "2068  3824   F      M         2    28220.80         N   38.95  38.766667   \n",
      "2069  3825   F      S         0    28589.10         N  100.28  15.600000   \n",
      "\n",
      "      RatePlan  LongDistance  ...  344  345  346       347  348  349  350  \\\n",
      "0            3         23.56  ...  0.0  0.0  0.0  0.209678  0.0  0.0  0.0   \n",
      "1            2         29.78  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "2            3         24.81  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "3            1         26.13  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "4            1          5.03  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "...        ...           ...  ...  ...  ...  ...       ...  ...  ...  ...   \n",
      "2065         4          0.37  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "2066         1         22.17  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "2067         4         28.92  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "2068         4         26.49  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "2069         3         13.19  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
      "\n",
      "      351  352  353  \n",
      "0     0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.0  \n",
      "...   ...  ...  ...  \n",
      "2065  0.0  0.0  0.0  \n",
      "2066  0.0  0.0  0.0  \n",
      "2067  0.0  0.0  0.0  \n",
      "2068  0.0  0.0  0.0  \n",
      "2069  0.0  0.0  0.0  \n",
      "\n",
      "[2070 rows x 370 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge files\n",
    "\n",
    "print(CustInfoData.shape)\n",
    "X_train = CustInfoData.drop(columns=[\"TARGET\"]) #extracting training data without the target column\n",
    "print(X_train.shape)\n",
    "combined=pd.concat([X_train, DF_TF_IDF], axis=1)\n",
    "print(combined.shape)\n",
    "print(combined)\n",
    "export_csv= combined.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/combined.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'Status', 'Car_Owner', 'Paymethod', 'LocalBilltype', 'LongDistanceBilltype']\n",
      "(2070, 378)\n"
     ]
    }
   ],
   "source": [
    "#Do one Hot encoding for categorical features\n",
    "X_cat = [\"Sex\",\"Status\",\"Car_Owner\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\"]\n",
    "#X_cat = combined.select_dtypes(exclude=['int','float64'])\n",
    "print(X_cat)\n",
    "combined_one_hot = pd.get_dummies(combined,columns=X_cat)\n",
    "print(combined_one_hot.shape)\n",
    "export_csv= combined_one_hot.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/combined_one_hot.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ID column as well before feature selection\n",
    "combined_one_hot = combined_one_hot.drop(columns=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 100)\n",
      "       0         1       2          3      4     5       6    7    8   \\\n",
      "0     1.0  38000.00  229.64  24.393333  23.56  0.00  206.08  0.0  0.0   \n",
      "1     2.0  29616.00   75.29  49.426667  29.78  0.00   45.50  0.0  0.0   \n",
      "2     0.0  19732.80   47.25  50.673333  24.81  0.00   22.44  0.0  0.0   \n",
      "3     2.0     96.33   59.01  56.473333  26.13  0.00   32.88  1.0  0.0   \n",
      "4     2.0  52004.80   28.14  25.140000   5.03  0.00   23.11  0.0  0.0   \n",
      "...   ...       ...     ...        ...    ...   ...     ...  ...  ...   \n",
      "2065  0.0  78851.30   29.04  48.373333   0.37  0.00   28.66  0.0  0.0   \n",
      "2066  1.0  17540.70   36.20  62.786667  22.17  0.57   13.45  0.0  0.0   \n",
      "2067  0.0  83891.90   74.40  61.020000  28.92  0.00   45.47  0.0  0.0   \n",
      "2068  2.0  28220.80   38.95  38.766667  26.49  0.00   12.46  0.0  0.0   \n",
      "2069  0.0  28589.10  100.28  15.600000  13.19  0.00   87.09  0.0  0.0   \n",
      "\n",
      "            9   ...   90   91   92   93   94   95   96   97   98   99  \n",
      "0     0.000000  ...  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  \n",
      "1     0.000000  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2     0.000000  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
      "3     0.000000  ...  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
      "4     0.000000  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  \n",
      "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2065  0.000000  ...  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
      "2066  0.000000  ...  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  \n",
      "2067  0.000000  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2068  0.772949  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
      "2069  0.000000  ...  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  \n",
      "\n",
      "[2070 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "#Feature selection using filtering\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "new_combined_one_hot_F = SelectKBest(score_func=chi2, k=100).fit_transform(combined_one_hot,y_train)\n",
    "print(new_combined_one_hot_F.shape)\n",
    "\n",
    "new_combined_one_hot_F= pd.DataFrame(new_combined_one_hot_F)\n",
    "print(new_combined_one_hot_F)\n",
    "\n",
    "export_csv= new_combined_one_hot_F.to_csv('/Users/rajatsuri/Desktop/Padhai/CIS 508/assig4/new_combined_one_hot_F.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split on Filter feature data\n",
    "X_train, X_test, y_train, y_test= train_test_split(new_combined_one_hot_F,y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1656, 100)\n",
      "(414, 100)\n",
      "(1656,)\n",
      "(414,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.969807\n",
      "Confusion Matrix:\n",
      "[[626  28]\n",
      " [ 22 980]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.97      0.96      0.96       654\n",
      "     Current       0.97      0.98      0.98      1002\n",
      "\n",
      "    accuracy                           0.97      1656\n",
      "   macro avg       0.97      0.97      0.97      1656\n",
      "weighted avg       0.97      0.97      0.97      1656\n",
      "\n",
      "Accuracy score (test): 0.852657\n",
      "Confusion Matrix:\n",
      "[[124  26]\n",
      " [ 35 229]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.78      0.83      0.80       150\n",
      "     Current       0.90      0.87      0.88       264\n",
      "\n",
      "    accuracy                           0.85       414\n",
      "   macro avg       0.84      0.85      0.84       414\n",
      "weighted avg       0.86      0.85      0.85       414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Random Forest Classifier on text data-Filtering\n",
    "clf=RandomForestClassifier()\n",
    "RF_text = clf.fit(X_train,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(clf.score(X_train, y_train)))\n",
    "rf_predictions = clf.predict(X_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rf_predictions))\n",
    "\n",
    "\n",
    "print(\"Accuracy score (test): {0:.6f}\".format(clf.score(X_test, y_test)))\n",
    "rf_predictions = clf.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.969807\n",
      "Confusion Matrix:\n",
      "[[639  15]\n",
      " [ 35 967]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.95      0.98      0.96       654\n",
      "     Current       0.98      0.97      0.97      1002\n",
      "\n",
      "    accuracy                           0.97      1656\n",
      "   macro avg       0.97      0.97      0.97      1656\n",
      "weighted avg       0.97      0.97      0.97      1656\n",
      "\n",
      "Accuracy score (test): 0.835749\n",
      "Confusion Matrix:\n",
      "[[126  24]\n",
      " [ 44 220]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.74      0.84      0.79       150\n",
      "     Current       0.90      0.83      0.87       264\n",
      "\n",
      "    accuracy                           0.84       414\n",
      "   macro avg       0.82      0.84      0.83       414\n",
      "weighted avg       0.84      0.84      0.84       414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a Decision Tree Classifier on text data-Filtering\n",
    "dtc=DecisionTreeClassifier()\n",
    "DT_text = dtc.fit(X_train,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(dtc.score(X_train, y_train)))\n",
    "dt_predictions = dtc.predict(X_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, dt_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, dt_predictions))\n",
    "\n",
    "print(\"Accuracy score (test): {0:.6f}\".format(dtc.score(X_test, y_test)))\n",
    "dt_predictions = dtc.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, dt_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 377 out of 377 | elapsed:  5.3min finished\n",
      "\n",
      "[2020-10-30 01:55:09] Features: 1/5 -- score: 0.8647342995169082[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 376 out of 376 | elapsed:  7.8min finished\n",
      "\n",
      "[2020-10-30 02:02:58] Features: 2/5 -- score: 0.8763285024154589[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed:  7.4min finished\n",
      "\n",
      "[2020-10-30 02:10:23] Features: 3/5 -- score: 0.8801932367149758[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:  8.2min finished\n",
      "\n",
      "[2020-10-30 02:18:37] Features: 4/5 -- score: 0.8830917874396136[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 22, 363]\n",
      "('Usage', 'Age', 'LongDistance', 13, 'Sex_F')\n",
      "0.8884057971014492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:  7.7min finished\n",
      "\n",
      "[2020-10-30 02:26:20] Features: 5/5 -- score: 0.8884057971014492"
     ]
    }
   ],
   "source": [
    "#Feature Selection Using Wrapper type-RandomForest\n",
    "\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "sfs1 = sfs(rfc,k_features=5,forward=True,floating=False,verbose=2, scoring='accuracy',cv=5)\n",
    "sfs1= sfs1.fit(combined_one_hot,y_train)\n",
    "\n",
    "#Select features from Random Forest\n",
    "\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)\n",
    "print(sfs1.k_feature_names_)\n",
    "print(sfs1.k_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84746419 0.82675184 0.813976   0.89566396 0.825      0.8390625\n",
      " 0.81875    0.821875   0.8171875  0.8765625  0.86369048 0.90119048\n",
      " 0.95456349 0.82400794 0.85238095 0.81825397 0.91825397 0.92619048\n",
      " 0.86031746 0.85575397]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "rfc_cv_score = cross_val_score(rfc,combined_one_hot,y_train, cv=20,scoring='balanced_accuracy')\n",
    "print(rfc_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split on Wrapper feature data-Random Forest\n",
    "\n",
    "sfs1_selected_features= combined_one_hot[['Usage', 'LongDistance',13, 'Sex_F', 'Paymethod_Auto']]\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "X_train, X_test, y_train, y_test= train_test_split(sfs1_selected_features,y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.924517\n",
      "Confusion Matrix:\n",
      "[[600  54]\n",
      " [ 71 931]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.89      0.92      0.91       654\n",
      "     Current       0.95      0.93      0.94      1002\n",
      "\n",
      "    accuracy                           0.92      1656\n",
      "   macro avg       0.92      0.92      0.92      1656\n",
      "weighted avg       0.93      0.92      0.92      1656\n",
      "\n",
      "Accuracy score (test): 0.862319\n",
      "Confusion Matrix:\n",
      "[[132  18]\n",
      " [ 39 225]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.77      0.88      0.82       150\n",
      "     Current       0.93      0.85      0.89       264\n",
      "\n",
      "    accuracy                           0.86       414\n",
      "   macro avg       0.85      0.87      0.86       414\n",
      "weighted avg       0.87      0.86      0.86       414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree on Test-Train Split data on Wrapper feature data-Random Forest\n",
    "dtc1=DecisionTreeClassifier()\n",
    "DT_text = dtc1.fit(X_train,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(dtc1.score(X_train, y_train)))\n",
    "dt_predictions = dtc1.predict(X_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, dt_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, dt_predictions))\n",
    "\n",
    "print(\"Accuracy score (test): {0:.6f}\".format(dtc1.score(X_test, y_test)))\n",
    "dt_predictions = dtc1.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, dt_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 377 out of 377 | elapsed:    7.4s finished\n",
      "\n",
      "[2020-10-30 02:28:46] Features: 1/5 -- score: 0.8657004830917874[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 376 out of 376 | elapsed:    9.1s finished\n",
      "\n",
      "[2020-10-30 02:28:55] Features: 2/5 -- score: 0.8734299516908213[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed:    9.2s finished\n",
      "\n",
      "[2020-10-30 02:29:04] Features: 3/5 -- score: 0.8782608695652174[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:   11.1s finished\n",
      "\n",
      "[2020-10-30 02:29:15] Features: 4/5 -- score: 0.881159420289855[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 20, 113, 363]\n",
      "('Usage', 'LongDistance', 11, 104, 'Sex_F')\n",
      "0.881159420289855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:    9.8s finished\n",
      "\n",
      "[2020-10-30 02:29:25] Features: 5/5 -- score: 0.881159420289855"
     ]
    }
   ],
   "source": [
    "#Feature Selection Using Wrapper type-Decision Tree\n",
    "\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "dt = DecisionTreeClassifier()\n",
    "sfs2 = sfs(dt,k_features=5,forward=True,floating=False,verbose=2, scoring='accuracy',cv=5)\n",
    "sfs2= sfs2.fit(combined_one_hot,y_train)\n",
    "feat_cols2 = list(sfs2.k_feature_idx_)\n",
    "print(feat_cols2)\n",
    "print(sfs2.k_feature_names_)\n",
    "print(sfs2.k_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78339141 0.81087882 0.89508324 0.86759582 0.825      0.865625\n",
      " 0.75625    0.7828125  0.8109375  0.83125    0.83650794 0.86825397\n",
      " 0.89325397 0.71170635 0.87281746 0.81488095 0.84107143 0.88531746\n",
      " 0.80357143 0.86150794]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "dt_cv_score = cross_val_score(dt,combined_one_hot,y_train, cv=20,scoring='balanced_accuracy')\n",
    "print(dt_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split on Wrapper feature data-Decision Tree\n",
    "\n",
    "sfs2_selected_features= combined_one_hot[['Usage', 'LongDistance', 11,104, 'Sex_F']]\n",
    "y_train = CustInfoData[\"TARGET\"]\n",
    "X_train, X_test, y_train, y_test= train_test_split(sfs2_selected_features,y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.922101\n",
      "Confusion Matrix:\n",
      "[[591  63]\n",
      " [ 66 936]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.90      0.90      0.90       654\n",
      "     Current       0.94      0.93      0.94      1002\n",
      "\n",
      "    accuracy                           0.92      1656\n",
      "   macro avg       0.92      0.92      0.92      1656\n",
      "weighted avg       0.92      0.92      0.92      1656\n",
      "\n",
      "Accuracy score (test): 0.857488\n",
      "Confusion Matrix:\n",
      "[[126  24]\n",
      " [ 35 229]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cancelled       0.78      0.84      0.81       150\n",
      "     Current       0.91      0.87      0.89       264\n",
      "\n",
      "    accuracy                           0.86       414\n",
      "   macro avg       0.84      0.85      0.85       414\n",
      "weighted avg       0.86      0.86      0.86       414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest on Test-Train Split data on Wrapper feature data-Decision Tree\n",
    "rfcc=RandomForestClassifier()\n",
    "rfcc_text = rfcc.fit(X_train,y_train)\n",
    "print(\"Accuracy score (training): {0:.6f}\".format(rfcc.score(X_train, y_train)))\n",
    "rfcc_predictions = rfcc.predict(X_train)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train, rfcc_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_train, rfcc_predictions))\n",
    "\n",
    "print(\"Accuracy score (test): {0:.6f}\".format(rfcc.score(X_test, y_test)))\n",
    "rfcc_predictions = rfcc.predict(X_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rfcc_predictions))\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, rfcc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
